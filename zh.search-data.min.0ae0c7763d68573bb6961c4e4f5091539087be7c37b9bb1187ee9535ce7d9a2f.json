[{"id":0,"href":"/v2rss-docs/zh/docs/player/cli/overview/","title":"Overview","section":"脚手架指令","content":"V2RSS 脚手架指令 #  基础指令 #  scaffold ping #  测试 Redis 数据库连接。  scaffold build #  在 Ubuntu 中构建基础运行环境。   订阅管理 #  scaffold pool #  订阅池的命令行管理工具。功能包括：剔除 alive_pool 中的失效订阅或过期订阅，输出订阅池状态等。    系统任务 #  scaffold deploy #  部署定时任务节点。  scaffold synergy #  部署协同工作节点。   scaffold server #  部署 PRODUCTION 接口服务器。  scaffold entropy #  采集队列的命令行管理工具。功能包括：更新待办任务、更新采集队列容量，检查待办任务心跳，输出采集队列摘要信息。   高级指令 #  scaffold mining #  采集、清洗、分类、存储暴露在公网上的 SSPanel-Uim 站点。  scaffold spawn #  释放所有本机采集实例，基于 gevent 并发执行。   实验功能 #  scaffold ash #  通过设定的 threshold 审查订阅池，清洗出各类订阅中的优质节点，重新排列组合生成可被 Clash 吸收的规则的 config.yaml ；自动打开 Clash 导入配置文件。    "},{"id":1,"href":"/v2rss-docs/zh/docs/user/bots/overview/","title":"Overview","section":"聊天机器人","content":"The bot revolution: Chatbots in automation #  Introduction to Chatbots #  「机器能否思考」这个问题历史悠久，早在1950年就已经存在， Alan Mathison Turing 提出了 图灵测试，用于测试机器能否表现出与人等价或无法区分的 智能。这一概念的现代应用常被用来帮助简化人类与信息系统之间的互动。\n「 聊天机器人」是一种能够模拟人类对话，与人类通过富文本或语音进行在线聊天对话的软件应用程序。在不断增长的数字世界中，聊天机器人已能生产环境中替代人类完成耗时的、繁琐的任务，如 客户服务或资讯获取。\n在顶层设计上，我们最常接触到的聊天机器人都具有两种属性，基于规则的应答和基于 NLP 的应答。\nRules-based Chatbots #  「响应式聊天机器人」也称基于规则的聊天机器人，它遵循预先确定的规则，常被用于功能性的引导场景。这是一个类似于流程图的过程，具有不同程度的复杂性，能够通过用户的输入获取一个映射结果。\n我们常见的群管理机器人都是基于规则的，它们的发言与其说是「交流」更像是「Response」，旨在以人们喜闻乐见的形式传达「指令已完成」的信号。\n真正意义上的「聊天机器人」是极其罕见的。绝大多多数具备闲聊能力的聊天机器人，都只将聊天功能作为外部请求的响应式玩具。意味着许多投放在生产中的聊天机器人仍然无法正常地与人类进行对话。\nLive Chatbots #  「即时聊天机器人」常被用以代替销售和技术支持团队实时回答问题。NLP 赋能的聊天机器人，可以更智能地理解用户的口语和输入问题，也能让我们实现效果更佳的多轮对话。这个新领域的成效远远超出了基于规则的响应式聊天机器人。\n然而，在「 新一代图灵测试」业界趋同的大背景下，我们并不需要执着于「cheat human」与「think like human」的区别，也不意味着无法闲聊的机器人就不能胜任「代人劳务」的工作。\nLimitations of Chatbots #  聊天机器人仍然是一个与人工智能和机器学习有很大关系的发展中的领域，因此其在功能和使用案例方面有一些难以处理的限制：\n  由于用于生成输出的数据库是固定和有限的，响应式聊天机器人在处理未知问题时可能会失败。\n  聊天机器人的工作效率高度依赖于语言处理，在语音对话中常受用户口音和口误等非范式行为的限制。\n  行业领先的聊天机器人已能在生产中处理多轮对话问题（通常认为「聊得越久越智能」），但仍无法很好地处理用户同时抛出的多个问题。\n业界关于一对多分支对话的解决方案各有千秋，而大多数投放于生产环境的聊天机器人用于特种领域（如上文所述），能于开放领域中与来自不同语言不同文化地区的人类对话的聊天机器人风毛菱角，效果差强人意。\n  性能优异的聊天机器人通常需要大量优质的对话数据来训练，所以目前行业中流行着「几家产品」与「一堆玩具」的诙谐盛况。\n  常规的聊天机器人难以管理非线性对话，必须与用户在同一类（个）话题上来回对话。\n目前，「全双工开放式领域对话」是一个行业领先的实践方案，但其依赖的动态回复与平行处理机制较为复杂，难以复现。\n  数据安全问题，主要来自数据污染（诱导）和接口爆破。\n  "},{"id":2,"href":"/v2rss-docs/zh/docs/user/v2rss-cli/overview/","title":"Overview","section":"云彩姬","content":" V2RSS 云彩姬 🚀 科学上网 从娃娃抓起\n     工具箱 #  云彩姬是一个与 V2RSS 开发者套件形成功能映射的包含「订阅获取」「生态抓取」「订阅发现」等多种组件的仪表盘工具箱。  跳板机 #  云彩姬不提供任何与「科学上网」有关的代理功能，但其各种组件「无需过墙」的特性能够在用户不幸失联时起到关键作用。  隐私透明 #  云彩姬尊重「用户隐私」；其本体基于 Easygui 设计，架构扁平透明，不包含除核心功能外的其他行为。   全协议采集 #  云彩姬能够主动识别并捕获订阅组链接。已覆盖主流协议订阅以及 Surge，Clash，Surfboard 等代理软件的配置策略。  操作门槛低 #  云彩姬将代理节点的分发行为降至零门槛。用户只要正常打开软体，几乎只需点击「下一步」就能获取到经过上游服务层层清洗的高质量订阅链接。  价值密度高 #  云彩姬分发的订阅已被打上各种价值标签。用户可以明确知道节点的过期时间与可用流量，而无需自建复杂的定时清洗任务，也无需亲自维护价值密度极低的代理节点池。   服务声明 🧙‍♂️ #  请项目使用者遵守如下约定，以免对你 我造成不必要的麻烦。\n 本项目开源免费，请不要滥用接口； 本项目软件及源码禁止在国内网络环境大范围传播； 禁止任何人使用本项目及其分支提供任何形式的收费代理服务。   "},{"id":3,"href":"/v2rss-docs/zh/docs/user/v2rss-shortcut/","title":"捷径","section":"使用指南","content":" V2RSS Shortcut #    「云彩姬捷径」（V2RSS Shortcut）是一个基于 捷径指令+ Shadowrocket URL Scheme 的订阅链接瞬时获取解决方案。\n  V2RSS 上游服务提供了一整套完备的订阅分发接口，iOS 用户仅需通过「云彩姬捷径」实现简单的 RPC 通信，便可拉取经过层层清洗的优质订阅节点。\n  「云彩姬捷径」共有 3 个大步骤，分别是接口请求，返回值清洗以及自启 Shadowrocket 并自动更新订阅。\n  Demo #  📌 若 shortcode 无法加载请访问 备用链接。    Quick Start #  下图为「云彩姬捷径」的模板代码。\n 展开内容 ↕  📌 为防止滥用，模板 步骤2 的测试接口已被隐去，用户若想使用属于自己的捷径指令，需要自行部署 V2RSS 上游服务。     "},{"id":4,"href":"/v2rss-docs/zh/docs/player/getting-started/overview/","title":"环境复现","section":"开始使用","content":"V2RSS 玩家手册 #   更新日期：2022/01/14\n 环境复现 #  📌 该项目基于 Windows 开发调试，基于 Linux 测试部署，MacOS 用户可能无法正常使用。  📌 v6.0.r-alpha 版本项目仍基于 Python 开发，暂未涉及 Go/Rust，也即本项目大部分高级功能暂未开源。     项目名 参考软件 备注     操作系统 Windows 10 ，Ubuntu20.04 LTS /   开发工具 PyCharm Community Edition Python3.8   数据库管理 RESP，Navicat Premium 15 数据库可视化管理   远程登录 Finalshell ，Xshell 远程服务器终端连接   开发依赖 google-chrome ， chromedriver 浏览器控制驱动   辅助工具（Win64） Anaconda Navigator 开发环境管理   辅助工具（Linux） pyenv，tmux 版本管理与会话管理    "},{"id":5,"href":"/v2rss-docs/zh/docs/player/cli/ping/","title":"Scaffold Ping","section":"脚手架指令","content":"Scaffold Ping #  NAME #  main.py ping - 测试 RedisNode 连接\nSYNOPSIS #  main.py ping - DESCRIPTION #  测试数据库连接。这是个不常用的功能，仅会在新环境首次创建时使用，如 在 GitHub Actions 中检查配置是否正确；在本地初次调试时，检查配置文件中 REDIS_NODE 是否配置正确等。\n"},{"id":6,"href":"/v2rss-docs/zh/docs/user/v2rss-cli/install/","title":"下载资源","section":"云彩姬","content":"下载资源 #  📌 云彩姬仅作 demo 使用，目前仅提供 Windows 发行客户端，暂无开发跨平台客户端的想法。  以你喜欢的方式拉取 V2RayCloudSpider 项目仓库 最新版本的发行客户端。下载解压获取 .exe 单体程序，双击运行既可启动云彩姬本姬。\n 展开插图 ↕      若您无法访问 GitHub 或不幸失联，也可以使用 CFW 反向代理加速下载。点击下方 Download 按钮既可加速下载 V2RSS云彩姬 v4.5.4 客户端，之后可通过软体内置模块拉取最新版本特性。\nDownload  "},{"id":7,"href":"/v2rss-docs/zh/docs/player/cli/build/","title":"Scaffold Build","section":"脚手架指令","content":"Scaffold Build #  NAME #  在 Ubuntu 白环境下构建运行环境。建议在 Ubuntu 18.04 TLS 或 Ubuntu 20.04 TLS 中使用。\nSYNOPSIS #  main.py build \u0026lt;flags\u0026gt; DESCRIPTION #  构建内容如下：\n  执行脚本 apt-get update \u0026amp;\u0026amp; apt-get install -y gcc wget unzip 更新源并拉取脚本运行所需依赖\n  检查 google-chrome 状态，若不存在则安装拉取最新稳定版 google-chrome 并返回版本号，若存在则直接返回当前客户端的版本号。\n若指定了 force  参数，本机已存在 google-chrome 时会卸载重装。\n  安装 chromedriver，根据 google-chrome 版本匹配相应版本的驱动。\n  移动 chromdriver 至指定目录下，并赋予 u+x 权限。\n  清理运行缓存（若权限不足则跳过）。清理安装包和下载缓存，清屏。\n  FLAGS #    force=FORCE\n  Type: Optional[bool]\n  Default: None\n若指定该参数，则当环境中已存在 google-chrome 时卸载重装。\n    "},{"id":8,"href":"/v2rss-docs/zh/docs/player/getting-started/quick-start/","title":"快速上手","section":"开始使用","content":"快速上手 #  快速部署一个可以采集订阅的 V2RSS 后端服务。\nLinux(Ubuntu) 📌 不建议使用国内厂商提供的 VPS 运行本项目。  📌 脚手架 build 脚本仅能在 Ubuntu 下运行。\n📌 系统服务是阻塞运行的，需要使用类似 tmux 之类的会话管理工具，否则连接断开后服务进程会被释放。\n  Fork 项目，拉取源码  git clone https://github.com/QIN2DIM/V2RayCloudSpider.git /home/v2rss-alpha 进入工作目录  cd /home/v2rss-alpha/V2RaycSpider1225  拉取必要依赖\n根据你的情况选择 pip/pip3 ，或使用 pyenv/conda 。\n  pip install -r ./requirements.txt 初始化组织结构以及配置文件  cd src \u0026amp;\u0026amp; python3 main.py build  再次执行，构建基础运行环境\n脚本构建的具体内容可参考 build 脚手架指令\n  python3 main.py build  修改配置文件\n打开位于 /home/v2rss-alpha/V2RaycSpider1225/src 目录下的 config.yaml，根据行内注释配置全局变量 REDIS_NODE，以及 POOL_CAP。其中 REDIS_NODE 需要玩家架设一个可远程访问的 Redis 节点。\n  测试连接\n若返回 欢迎使用 字样说明配置文件编写以及节点配置都没问题，可以正常运行项目了。\n  python3 main.py ping 初始化服务对象  # Create Remote EntropyHeap Object. python3 main.py entropy --update # Set Unified Pool Capacity. python3 main.py entropy --cap=8 试运行采集器  cd /home/v2rss-alpha/V2RaycSpider1225 \u0026amp;\u0026amp; python3 examples/atomic_go.py 若出现类似如下的日志信息，说明驱动器配置正确，可以部署服务了。\n2022-01-14 14:52:50 | DEBUG - \u0026gt;\u0026gt; RUN [ActionMaSaiKeCloud] - params={\u0026#39;aff\u0026#39;: 5, \u0026#39;threshold\u0026#39;: 3} 2022-01-14 14:52:56 | SUCCESS - \u0026gt;\u0026gt; STORE [ActionMaSaiKeCloud] - subscribe_url=https://ma.sai.ke?sub=3 部署系统服务  📌 如下三个系统服务均为独立的阻塞进程，如果都要在同一台物理机上部署，需要开启多个会话窗格操作。\n📌 可在「 脚手架指令」查看关于 deploy ，synergy 以及 server 的详细介绍。\n # 部署系统 任务 cd /home/v2rss-alpha/V2RaycSpider1225/src \u0026amp;\u0026amp; python3 main.py deploy # 部署协同工作节点 cd /home/v2rss-alpha/V2RaycSpider1225/src \u0026amp;\u0026amp; python3 main.py synergy # 部署 PRODUCTION 接口服务器 cd /home/v2rss-alpha/V2RaycSpider1225/src \u0026amp;\u0026amp; python3 main.py server --host=0.0.0.0 --port=22333 Windows  "},{"id":9,"href":"/v2rss-docs/zh/docs/user/v2rss-cli/quick-start/","title":"快速上手","section":"云彩姬","content":"订阅链接「快速获取」 #  📌 部分订阅源拒绝国内 IP 访问，需要使用代理才能正常更新订阅。  在 Home 首页下，（以获取 V2Ray 订阅链接为例）依次选择 [2]获取订阅链接 [1]V2Ray订阅链接 既可获取订阅，如下图所示：\n 展开插图 ↕       本组件需联网使用，下图为「获取成功」的界面，点击 OK 既可自动复制链接。\n 展开插图 ↕      打开你喜欢的图形客户端，按下 Ctrl + V 既可自动添加订阅链接，更新订阅后既可拉取订阅映射的节点列表。\n 云彩姬支持主流协议订阅的采集，其他类型订阅的快速获取方法均可类比。\n 订阅链接「查询获取」 #  📌 在上一步方案中，快速获取的订阅由上游服务随机分发，而云彩姬允许使用者选取订阅。  在Home首页下，依次选择[2]获取订阅链接-\u0026gt;[4]查询可用链接，即可弹出下图所示界面。\n 展开插图 ↕      此窗格由 3 部分信息组成，分别为「过期时间」「订阅类型」以及「订阅别名」，过期时间以 Asia/Shanghai 为准。\n查看「访问历史」 #  这是个不常用的功能，主要用于解决一些棘手的需求场景 。例如用户在「获取成功」界面点击 OK 后，相关信息会自动流入剪贴板而后窗体自行消解，若此时有其他信息混入剪贴板，使用者又不知道如何查看剪贴板历史时，可使用「查看访问历史」功能捕获游离的数据。\n在Home首页下，选择 [3]打开本地文件 查看历史请求记录。\n 展开插图 ↕   \t   查看「机场生态」 #  📌 云彩姬内置高性能抓取模块，能够充分利用本地网络资源采集机场生态。  📌 因不可抗力因素此插件不再更新。  获取数据\n在 Home 首页下，依次选择[1]查看机场生态，[any]，[1]查看，既可查看 free/vip/all 三个层级的数据，选中项目并敲下 Enter 使用默认浏览器访问对应提供商的注册页面（部分网站需要代理访问）。\n 展开插图 ↕      保存数据\n在 Home 首页下，依次选择 [1]查看机场生态，[any]，[2]保存，既可保存 free/vip/all 三个层级的对应信息。\n 展开插图 ↕      "},{"id":10,"href":"/v2rss-docs/zh/docs/user/v2rss-cli/toc/","title":"注意事项","section":"云彩姬","content":"注意事项 #  进程冻结 #  📌 云彩姬会主动限制用户的请求频率。  软件内置的进程锁函数将综合 本地请求历史 与 服务时区残差 等多种因素锁死进程。封禁时间一般位于 15~45s 之间。\n 展开插图 ↕      其他声明 #    云彩姬是一个由维护者提供的用于项目演示的 demo，并不是一个成熟的生产工具。\n  若您在使用过程中遇到 响应迟钝，窗体消失 等问题，请检查您当前的网络状况，等待数秒后仍无响应请重启软件。\n  若无特殊需求，本项目 Panel （云彩姬）将不再升级或更新，其余项目进度将在 Projects 中公示。\n  无论是使用过程中遇到的困难，还是有关本项目的需求建议，您都可以在 issue 中留言。\n   "},{"id":11,"href":"/v2rss-docs/zh/docs/player/getting-started/install-v2rss/","title":"源码下载","section":"开始使用","content":"源码下载 #  "},{"id":12,"href":"/v2rss-docs/zh/docs/player/getting-started/basic-usage/","title":"基本用法","section":"开始使用","content":"基本用法 #  "},{"id":13,"href":"/v2rss-docs/zh/docs/player/getting-started/directory-structure/","title":"目录结构","section":"开始使用","content":"目录结构 #  New Project Scaffolding #  若玩家直接使用 git 指令拉取源码仓库，那仅需关注其中的 V2RaycSpider[KernelCode] 文件夹，如下目录结构以此为根展开介绍。\n. ├── examples │ ├── __init__.py │ ├── atomic_assault.py │ ├── atomic_check.py │ ├── atomic_go.py │ └── server_dev.py ├── src │ ├── apis │ ├── database │ ├── driver │ ├── services │ ├── __init__.py │ ├── config.py │ ├── config.yaml │ ├── config-sample.yaml │ └── main.py └── requirements.txt Directory Structure Explained #  examples #  这里存放一些精简化的后端功能接口，玩家可通过这些运行案例迅速了解服务间的层级关系以及核心业务的实现逻辑。其中，server_dev.py 启动的一个 dev 环境的接口服务器；atomic_go.py 启动一个指定的采集实例，可通过修改 alias 指定不同的采集实例；atomic_assault.py 则是实例运行的 gevent 版本，可并发地执行多个采集实例；atomic_check.py 用于检查本地采集队列的健康状态。\n值得一提的是，这些功能都可通过脚手架快速调用，放在这主要便于扁平化的案例介绍。\nsrc/apis #  存放全局接口函数，如一些复杂的脚手架接口逻辑会在此编排。\nsrc/database #  存放系统运行缓存。在项目初始化后，此文件夹被自动创建。\nsrc/driver #  存放 chromedriver 驱动程序。在项目初始化后，此文件夹被自动创建。\nsrc/services #  存放核心业务代码，包括如下内容：\n. ├── app │ ├── bot │ ├── panel │ ├── server │ └── __init__.py ├── collector │ ├── nest │ ├── __init__.py │ ├── actions.py │ ├── core.py │ ├── exceptions.py │ └── operator.py ├── decoupler │ ├── __init__.py │ └── decoupler.py ├── middleware │ ├── __init__.py │ ├── stream_io.py │ ├── subscribe_io.py │ └── workers_io.py ├── utils │ ├── accelerator │ ├── armor │ ├── sspanel_mining │ ├── toolbox │ └── __init__.py ├── __init__.py ├── deploy.py ├── scaffold.py └── settings.py   app\n存放接口服务器模型。可见，目前云彩姬支持以聊天机器人（Nonebot、Telegram-bot、DingTalk-bot\u0026hellip;\u0026hellip;）、PC客户端面板、以及API接口的形式分发订阅。\n  collector\n采集器逻辑层代码。core.py 存放核心业务代码，包含采集器整个周期的行为函数；actions.py 维护一个 __entropy__ 本地采集队列，存放着采集实例的上下文摘要信息；operator.py 存放着一个接口解释器，输入 atomic_context ，输出一个特征完整的采集实例；exceptions.py 存放采集器运行时常见的报错类型。\n  decoupler\n订阅解耦器，核心功能是清楚失效订阅。\n  middleware\n数据库交互层。stream_io.py 存放各类型数据库的基准链接方案；subscribe_io.py 存放着继承自 RedisClient 基类的高级逻辑代码，负责管理订阅池；workers_io.py 存放着继承自 RedisClient 基类的高级逻辑代码，包含任务堆管理，消息队列，访问控制等模块。\n  utils\n可移植模组。存放着云彩姬生态的可移植模组，包含 accelerator 协程加速组件，云彩姬后端服务是基于协程运转的，此组件基于 Gevent 构建了一个可管理的极其轻量的并发框架；armor 存放着一系列人机对抗组件，通过适配器接口无缝衔接至采集器的生命周期中；sspanel_mining 是项目 RobAI-Lab/ sspanel-mining 的兼容版本，可通过脚手架 mining 指令运行；toolbox 存放着若干个工具类函数，包括构建基础环境的 build 脚本，InitLog 自定义日志，SubscribeParser 订阅解析，以及包含着各种常用功能的ToolBox工具箱。\n  deploy.py\n系统任务的调度中心。\n  scaffold.py\n脚手架源码。\n  settings.py\n系统设置。设定全局变量用于精确的绝对路径定位，初始化系统日志，引用 src/config.py 中的配置信息。\n  src/config.yaml #  项目配置文件。在项目初始化后，从 src/config_sample.yaml 拷贝生成。 src/config.py 的功能是读取配置信息并转义成 Python 全局变量。\n关于配置文件的具体介绍可见「 CONFIGURATION」。\nsrc/main.py #  脚手架入口文件，作为运行根辐射系统指令，在脚手架未编译前，作为系统指令的统一入口。\n"},{"id":14,"href":"/v2rss-docs/zh/docs/player/getting-started/configuration/","title":"项目配置","section":"开始使用","content":"项目配置 #  "},{"id":15,"href":"/v2rss-docs/zh/docs/player/cli/pool/","title":"Scaffold Pool","section":"脚手架指令","content":"Scaffold Pool #  NAME #  main.py pool - 订阅池管理\nSYNOPSIS #  main.py pool \u0026lt;flags\u0026gt; DESCRIPTION #  订阅池的命令行管理工具。功能包括：清除 alive_pool 中的失效订阅或过期订阅，输出订阅池状态等。\nUsage: python main.py pool ______________________________________________________________________ or: python main.py pool --decouple\t|清除失效订阅 or: python main.py pool --overdue\t|清除过期订阅 ______________________________________________________________________ alive_pool 失效订阅 #  此处定义的失效指：无法通过ping测试，订阅接口返回值为空或不符合预期。因此，若订阅已“过期”，它显然是“失效”的。\n正常状态的订阅接口一般情况下会返回一串 BASE64 编码内容，通过编码转换后可解析出节点链接。\nalive_pool 过期订阅 #  每个采集实例都有一个固定的 life_cycle 生命周期（默认24小时），对应着订阅节点的试用时长。\n广义上的过期指的是自然时间大于 life_cycle ，订阅的生命周期结束，已失效。而此处的“过期”具有更丰富的含义。\n采集实例的上下文超级参数 hyper_params 中设定了 threshold 关键字，默认值为 3（小时），它表示将订阅的生命周期提前/缩短 threshold 小时。而系统定时任务中的 overde_job 接收的正是计算了此关键字的 life_cycle。\n设定此关键字的目的可想而知，过期只是某个时刻的概念，只要还没到那个时刻就不会被清除。此时玩家取链接很可能获取到仅剩几秒就（广义）过期的订阅，所以设置此关键词，确保玩家在最恶劣的情况下，仍能取到至少能坚挺 threshold 小时的订阅节点。\nalive_pool 订阅池状态 #  在介绍订阅池状态前需要介绍 alive action-alias 的概念。alive action-alias 是作者为了降低任务编排难度，为每个可调度的采集实例设定的全局唯一ID，其格式为 Action[Name]Cloud，如 ActionModuCloud ，对应着一个独立采集实例。\n查看订阅池状态，就是查看每个 alive action-alias 的剩余数量。若请求成功，可返回如下格式信息：\n(v2rss-alpha) E:\\_GithubProjects\\Sources\\v2raycs_dev\\src\u0026gt;python main.py pool [2022-01-14 12:06:01] [✓] {\u0026#39;ActionFETVCloud\u0026#39;: 3, \u0026#39;ActionShyNiaCloud\u0026#39;: 2, \u0026#39;ActionCheapCloud\u0026#39;: 1, \u0026#39;ActionAaxCloud\u0026#39;: 2} FLAGS #    overdue=OVERDUE\n  Type: bool\n  Default: False\n清除过期订阅（decouple 与 overdue 仅能同时执行一项）\n    decouple=DECOUPLE\n  Type: bool\n  Default: False\n清除失效订阅（decouple 与 overdue 仅能同时执行一项）\n    status=STATUS\n  Type: bool\n  Default: True\n输出订阅池状态（不指定执行参数时默认输出）\n    "},{"id":16,"href":"/v2rss-docs/zh/docs/player/cli/deploy/","title":"Scaffold Deploy","section":"脚手架指令","content":"Scaffold Deploy #  NAME #  main.py deploy - 部署系统定时任务\nSYNOPSIS #  main.py deploy \u0026lt;flags\u0026gt; DESCRIPTION #  部署系统定时任务。\nUsage: python main.py deploy ______________________________________________________________________ or: python main.py deploy --collector=False |强制关闭采集器 or: python main.py deploy --collector |强制开启采集器 or: python main.py deploy --collector --decoupler |强制开启采集器和订阅解耦器 ______________________________________________________________________  初次部署前先运行 python main.py entropy --update 初始化远程队列。 命令行参数的优先级高于配置文件。 不使用参数启动时，相关配置以配置文件为准。  定时任务包括如下内容：\n collector： 采集器任务（与 overdue_job 捆绑）。 decoupler： 订阅解耦任务，用于清除失效订阅。  需要注意的是，配置文件中设定了默认的 launch_interval 任务发起间隔，玩家自定义的间隔数不得小于默认值，否则任务无法部署（或强制调回默认值启动）。\nFLAGS #    collector=COLLECTOR\n  Type: Optional[bool]\n  Default: None\n强制开启/关闭采集器\n    decoupler=DECOUPLER\n  Type: Optional[bool]\n  Default: None\n强制开启/关闭订阅解耦器\n    "},{"id":17,"href":"/v2rss-docs/zh/docs/player/cli/synergy/","title":"Scaffold Synergy","section":"脚手架指令","content":"Scaffold Synergy #  NAME #  main.py synergy - 部署协同工作节点\nSYNOPSIS #  main.py synergy - DESCRIPTION #  INTRO #  在介绍 协同工作 的概念前，需要先了解以下与之相关的背景知识。\n在采集实例上下文超级参数 hyper_params 中设定了 aff 和 synergy 两个关键字。\n aff=AFF  Type:Optional[int] Default:0 协同机拷贝数   synergy=SYNERGY  TypeOptional[bool] Default:False 协同模式/采集模式上下文切换    AFF #  aff 凭借提供商“佣金返利”的商业模式，携带被增益订阅的邀请链接进行多对一的协同注册，简单实现被增益订阅可用流量的拔升。每个提供商的“返利”规则大有不同，账户邀请链接数和增益流量大相径庭。\n因此，并不是任何一个采集实例都可以设定 aff 参数，也并不是所有可以设定 aff 参数的采集实例都值得被增益，部分规则的返利流量实在太少，相对的采集成本较大，在拥有性价比更高的选择时，可以忽略。\n显然的，aff 的设定需要遵循规则，其因该是一个大于零的自然数，且不应多于规则限制的可邀请数量。在最佳实践中，aff∈[1,10] 这在源码中也加以限制，当玩家设定的 aff 超乎预期时，协同实例的拷贝逻辑将失效。\nSYNERGY #  由上文可知，当采集实例正常结束前，会进行 aff 超级参数的解析，若含义有效，则会拷贝 aff 个切换至协同模式的实例通过 MessageQueue(RedisClient) 广播至订阅频道。需要注意的是，这个广播出去的信息是一个完整的（处于协同模式的）运行实例对象的「上下文摘要」，监听此频道的 synergy 服务节点都可以正常过滤解析这些字段，并通过一系列逻辑将摘要信息恢复成实例运行所需的各项参数，最后执行协同注册任务。\nSYNERGY PATTERN #  到了正式介绍 协同工作 模式的时候了。使用如下指令可拉起一个协同工作进程，显然地，它不需要任何脚手架参数。\npython main.py synergy   synergy pattern 的指令逻辑被精简优化，可部署到任意的物理机上，甚至一台物理机可以部署多个 synergy 服务节点。\n  处于 协同模式 的服务节点几乎只做三件事： 接受 aff 上下文信息，恢复现场，执行协同注册任务。\n  synergy_node 基于 APScheduler 运行，节点宕机可被自动拉起恢复工作。\n  处于 协同模式 的服务节点可以长期工作。只要核心业务代码不做升级，synergy_node可以一直运行下去，如上文所说，synergy_node可以正常解码任务信息并执行指定任务，无论我们再怎么更新采集队列，变换队列容量或属性，甚至拓展采集器的业务逻辑，只要不改动上下文摘要的“通信协议头”，synergy_node就能不停机地一直工作下去（若协议头不匹配，会把无法解析的消息当成杂质过滤掉）。\n  "},{"id":18,"href":"/v2rss-docs/zh/docs/player/cli/server/","title":"Scaffold Server","section":"脚手架指令","content":"Scaffold Server #  NAME #  main.py server - PRODUCTION 接口服务器（仅在linux部署时生效）\nSYNOPSYS #  main.py server \u0026lt;flags\u0026gt; DESCRIPTION #   查看接口文档 ↕  点此 查看接口文档，访问密码：y2WZHeHF    脚手架基础用法如下：\nUsage: python main.py server ______________________________________________________________________ or: python main.py server --host=127.0.0.1 --port=22332 |指定端口运行 or: python main.py server --detach=False |订阅耦合 ______________________________________________________________________ 📌 为了在生产环境下获得最佳性能，默认禁用 debug 和 access_log。  📌 Sanic 可指定 workers 充分利用多核性能，也可直接指定 --fast 参数直接拉满，子进程间可以负载均衡。而云彩姬服务端口仅供个人使用，不存在高并发的应用场景，也即 workers=1 既可（默认），无需更改指定，徒增功耗。  📌 通过此指令直接运行的是生产服务器，若要运行开发环境调试代码，请手动运行 examples/server_dev.py 或 src/services/app/server。  FLAGS #    host=HOST\n Type: Optional[str] Default: None    port=PORT\n Type: Optional[int] Default: None    detach=DETACH\n  Type: Optional[bool]\n  Default: None\n分离订阅（不指定时默认为 True）。若 detach is True，通过接口层申请的订阅才会被系统删除。 意味着在接口调试时，指定 detach=False 被请求的链接不会被删除。\n    "},{"id":19,"href":"/v2rss-docs/zh/docs/player/cli/entropy/","title":"Scaffold Entropy","section":"脚手架指令","content":"Scaffold Entropy #  NAME #  main.py entropy - 采集队列的命令行管理工具。\nSYNOPSIS #  main.py entropy \u0026lt;flags\u0026gt; DESCRIPTION #  采集队列的命令行管理工具。功能包括：更新待办任务、更新采集队列容量，检查待办任务心跳，输出采集队列摘要信息。基础用法如下：\nUsage: python main.py entropy ______________________________________________________________________ or: python main.py entropy --remote |输出 `远程执行队列` 的摘要信息 or: python main.py entropy --update |将 `本地执行队列` 辐射至远端 or: python main.py entropy --check |检查 `本地执行队列` 的健康状态 or: python main.py entropy --cap |将 `POOL_CAP` 队列容量映射到远端 or: python main.py entropy --cap=8 |手动修改远程队列容量 ______________________________________________________________________ Remote Entropy Heap #  在 v6.0.1-alpha 之后，采集器默认使用「远程共享队列」同步待办任务。意味着采集节点不再关心其所在物理服务器中的 __entropy__ 列表，而是 Remote EntropyHeap 对象。\nRemote EntropyHeap Object 存储着若干个采集实例的上下文摘要信息，采集器读取这些数据后，根据一系列的生产逻辑，输出符合特征的实例，进而启动采集任务。\n手动修改 Remote EntropyHeap 需要执行 python main.py entropy --update 更新远程共享队列，此时所有采集器节点都会使用新的任务队列。切换操作是立即完成的，在采集器下一次任务预加载时生效。\n项目初始化时 Remote EntropyHeap 并不存在，直接执行脚手架 deploy 指令部署采集器后必然会保持空转，也即需要在项目初始化后执行一次 python main.py entropy --update 用以创建 Remote EntropyHeap，这样采集器才会读取到待办任务。\n--update 的逻辑是将本地的 __entropy__ 辐射到远端，一般在管理员服务器上使用（比如你的本地电脑）。 在后期运维中，管理员发现新的可执行实例时，可以手动编写上下文摘要信息，录入 __entropy__，再使用此指令辐射到远程任务队列中。\nUnified Pool Capacity #  在 v6.0.2-alpha 之后，可以通过脚手架指令 entropy --cap 手动指定远程队列容量，同步操作是立即完成的，将在采集器下次任务预加载时生效。\n此指令不会覆盖本地 POOL_CAP 全局变量的值，也不会覆写任一节点的配置文件，而是创建或更新一个指定的 Redis-Key。\nEntropy Heartbeat #  --check 指令可以检查本地队列的健康状态，如摘要信息是否配置正确，register_url 的通信状态等。\nEntropy Status #  不携带参数运行可以在控制台输出本地采集队列的摘要信息，添加 --remote 参数则输出远程队列的。\nFLAGS #    update=UPDATE\n  Type: bool\n  Default: False\n将 本地执行队列 辐射至远端\n    remote=REMOTE\n  Type: bool\n  Default: False\n输出 远程执行队列 的摘要信息\n    check=CHECK\n  Type: bool\n  Default: False\n检查 本地执行队列 的健康状态\n    cap=CAP\n  Type: Optional[int]\n  Default: None\n修改远程队列容量\n    "},{"id":20,"href":"/v2rss-docs/zh/docs/player/cli/mining/","title":"Scaffold Mining","section":"脚手架指令","content":"Scaffold Mining #  NAME #  main.py mining - 采集、清洗、分类、存储暴露在公网上的 SSPanel-Uim 站点。\nSYNOPSIS #  main.py mining \u0026lt;flags\u0026gt; DESCRIPTION #  📌 详见分支项目 SSPanel-Mining。  📌 访客可在 运行缓存 中阅览分类结果。  基础用法如下：\nUsage: python main.py mining ______________________________________________________________________ or: python main.py mining --env=production |在 GitHub Actions 中构建生产环境 or: python main.py mining --silence=False |显式启动，在 linux 中运行时无效 or: python main.py mining --power=4 |指定分类器运行功率 or: python main.py mining --classifier --source=local |启动分类器，指定数据源为本地缓存 or: python main.py mining --classifier --source=remote |启动分类器，指定远程数据源 or: python main.py mining --collector |启动采集器 ______________________________________________________________________ FLAGS #    env=ENV\n  Type: str\n  Default: \u0026lsquo;development\u0026rsquo;\nMust be within [development production]\n    silence=SILENCE\n  Type: bool\n  Default: True\n采集器静默启动。\n    power=POWER\n  Type: int\n  Default: 16\n分类器运行功率。\n    collector=COLLECTOR\n  Type: bool\n  Default: False\n采集器运行权限。\n    classifier=CLASSIFIER\n  Type: bool\n  Default: False\n分类器控制权限。\n    source=SOURCE\n  Type: str\n  Default: \u0026lsquo;local\u0026rsquo;\n该参数仅对分类器生效，Must be within [local remote] 用于指定数据源。\n local：使用本地 Collector 采集的数据进行分类 ； remote：使用 SSPanel-Mining 母仓库数据进行分类（需要下载数据集）。      batch=BATCH\n  Type: int\n  Default: 1\nbatch 应是大于零的自然数，该参数仅在 source==remote 时生效，用于指定拉取的数据范围。\n batch=1 表示拉取昨天的数据（默认）； batch=2 表示拉取昨天+前天的数据，以此类推往前堆叠 显然，当设置的 batch 大于母仓库存储量时会自动截停运行逻辑，防止溢出。      DEMO #   指令运行 ↕      查看运行结果 ↕     "},{"id":21,"href":"/v2rss-docs/zh/docs/player/cli/spawn/","title":"Scaffold Spawn","section":"脚手架指令","content":"Scaffold Spawn #  NAME #  main.py spawn - 释放所有本机采集实例，基于 gevent 并发执行。\nSYNOPSIS #  main.py spawn \u0026lt;flags\u0026gt; DESCRIPTION #  基础用法如下：\nUsage: python main.py nest ______________________________________________________________________ or: python main.py nest --power=4 |指定并发数 or: python main.py nest --remote |读取远程队列的运行实例 or: python main.py nest --safe |安全启动，过滤掉需要人机验证的任务 ______________________________________________________________________ 在最佳实践中，仅推荐在调试阶段需要快速补充订阅池的情况下使用，否则请使用 examples/atomic_go.py 中的应用案例，通过修改 alias 运行指定的采集实例。\n这是个对本机硬件配置要求极高的指令，不推荐在少于 16G 内存且代理网速不佳的状态下使用。\nFLAGS #   silence=SILENCE  Type: bool Default: True 静默启动   power=POWER  Type: Optional[int] Default: None 指定并发数   remote=REMOTE  Type: bool Default: False 将任务队列标记为 远程队列   safe=SAFE  Type: bool Default: False 安全启动，过滤掉需要人机验证的实例    "},{"id":22,"href":"/v2rss-docs/zh/docs/player/cli/ash/","title":"Scaffold Ash","section":"脚手架指令","content":"Scaffold Ash #   清洗订阅池，筛选出高可用订阅并转换为 config.yaml 配置文件； 借由 URL Scheme 自启 Clash for Windows 并自动拉取代理节点；  Runtime Demo #  uTools 一键拉取 #  演示 Windows 用户通由 QuickComment 快捷指令运行脚本，实现 Clash for Windows 订阅拉取功能。  Terminal 运行指令 #  演示 Windows 用户通由 Terminal 运行指令，实现订阅清洗、优选、转换并封装输出 Clash URL-Scheme 的过程。之后演示实验环境下的 Youtube 4K video 码率表现。   "}]